# ðŸ“„ DocumentReader - Simple GenAI App (Single-File Version)

A minimal Generative AI-powered document reader built with **Streamlit**, **LangChain**, and **Ollama** using only a single Python script (`app.py`). Upload a link, ask any question about its content, and get context-aware responses powered by LLaMA 3 2.1B.

---

## Features

- load links
- Ask natural language questions based on document content
- Uses Retrieval with LangChain
- Powered by a local Ollama LLM (e.g. `llama3 2.1B`)
- Single-file Python app for fast setup and demo

---

## Tech Stack

- Python
- [LangChain](https://www.langchain.com/)
- [Ollama](https://ollama.com/)
---

## Installation
---
### 1. Clone the Repository

```
git clone https://github.com/Pooja-Arumugam/DocumentReader-simple-GenAI-App-.git
cd DocumentReader-simple-GenAI-App-

### 2. Create Virtual Environment

```
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

### 3. Install Requirements
```
pip install -r requirements.txt

### 4. Setup Environment Variables
```
Create a .env file in the project root:
LANGCHAIN_API_KEY=your_langchain_api_key
LANGCHAIN_PROJECT=DocumentReader

### 5. Download Ollama Model
```
Make sure you have Ollama installed and running:(local)
ollama run llama3

---

## How It Works

1. Upload your document using the Streamlit interface  
2. The document is chunked and embedded using LangChain  
3. Your query is processed using **LLM + context** 
4. The response is displayed on the screen  

---

##  Example

- Upload: any link of your choice  
- Ask: _"Summarize the financial highlights"_  
- Answer: _(context-aware summary generated by LLaMA3)_

---

##  Author

**Pooja Arumugam**  
---


## Contributing

If you find bugs or want to improve the app, feel free to:

- Create a new branch  
- Submit a pull request  

---

## Coming Soon

- Multiple file upload  
- Conversational memory  
- Support for Excel files

